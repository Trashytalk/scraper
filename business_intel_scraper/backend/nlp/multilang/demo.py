#!/usr/bin/env python3
"""
Multi-Language NLP Integration Demo

Demonstrates the complete multi-language NLP system for business intelligence.
Run this script to test all components with sample data.
"""

import asyncio
import logging
from typing import List, Dict, Any

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def print_section(title: str):
    """Print formatted section header"""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print('='*60)

def print_subsection(title: str):
    """Print formatted subsection header"""
    print(f"\n{'-'*40}")
    print(f"  {title}")
    print('-'*40)

def main():
    """Main demonstration function"""
    print_section("Multi-Language NLP System Demo")
    
    # Sample texts in different languages
    sample_texts = {
        'English': "Apple Inc. is located at 1 Apple Park Way, Cupertino, CA 95014, USA. Revenue: $365.8B. Contact: +1-408-996-1010.",
        'Chinese': "ËãπÊûúÂÖ¨Âè∏‰Ωç‰∫éÁæéÂõΩÂä†Âà©Á¶èÂ∞º‰∫öÂ∑ûÂ∫ìÊØîËíÇËØ∫ËãπÊûúÂÖ¨Âõ≠Â§ßÈÅì1Âè∑ÔºåÈÇÆÁºñ95014„ÄÇËê•Êî∂3658‰∫øÁæéÂÖÉ„ÄÇÁîµËØùÔºö+1-408-996-1010„ÄÇ",
        'Russian': "–Ø–Ω–¥–µ–∫—Å —è–≤–ª—è–µ—Ç—Å—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –∫–æ–º–ø–∞–Ω–∏–µ–π. –ê–¥—Ä–µ—Å: –ú–æ—Å–∫–≤–∞, —É–ª. –õ—å–≤–∞ –¢–æ–ª—Å—Ç–æ–≥–æ, –¥. 16. –î–æ—Ö–æ–¥: 280 –º–ª—Ä–¥ —Ä—É–±. –¢–µ–ª–µ—Ñ–æ–Ω: +7-495-739-70-00.",
        'Arabic': "ÿ£ÿ±ÿßŸÖŸÉŸà ÿßŸÑÿ≥ÿπŸàÿØŸäÿ© ÿ¥ÿ±ŸÉÿ© ŸÜŸÅÿ∑ ÿ≥ÿπŸàÿØŸäÿ©. ÿßŸÑÿπŸÜŸàÿßŸÜ: ÿßŸÑÿ∏Ÿáÿ±ÿßŸÜÿå ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©. ÿßŸÑÿØÿÆŸÑ: 400 ŸÖŸÑŸäÿßÿ± ÿØŸàŸÑÿßÿ±. ÿßŸÑŸáÿßÿ™ŸÅ: +966-13-872-7000.",
        'Japanese': "„Éà„É®„ÇøËá™ÂãïËªäÊ†™Âºè‰ºöÁ§æ„ÅØÊó•Êú¨„ÅÆËá™ÂãïËªä„É°„Éº„Ç´„Éº„Åß„Åô„ÄÇ‰ΩèÊâÄÔºöÊÑõÁü•ÁúåË±äÁî∞Â∏Ç„Éà„É®„ÇøÁî∫1Áï™Âú∞„ÄÇÂ£≤‰∏äÔºö30ÂÖÜÂÜÜ„ÄÇÈõªË©±Ôºö+81-565-28-2121„ÄÇ",
        'Spanish': "Banco Santander tiene sede en Madrid, Espa√±a. Direcci√≥n: Paseo de la Castellana 24. Ingresos: ‚Ç¨50.2B. Tel√©fono: +34-91-289-0000.",
        'German': "SAP SE hat ihren Sitz in Weinheim, Deutschland. Adresse: Dietmar-Hopp-Allee 16. Umsatz: ‚Ç¨27.8B. Telefon: +49-6227-7-47474.",
        'French': "Total SE est une compagnie fran√ßaise. Adresse: 2 Place Jean Millier, La D√©fense. Chiffre d'affaires: ‚Ç¨140B. T√©l√©phone: +33-1-47-44-45-46."
    }
    
    try:
        # Import the multi-language processor
        try:
            from business_intel_scraper.backend.nlp.multilang import multilang_processor
            HAS_MULTILANG = True
        except ImportError as e:
            logger.warning(f"Multi-language processor not available: {e}")
            HAS_MULTILANG = False
            
        if not HAS_MULTILANG:
            print("‚ùå Multi-language processor not available")
            print("Please install dependencies: pip install -r requirements.txt")
            return
            
        # Test 1: Language Detection
        print_section("1. Language Detection Test")
        
        for lang_name, text in sample_texts.items():
            try:
                detected = multilang_processor.detector.create_detected_text(text)
                print(f"üîç {lang_name:10} ‚Üí {detected.language.name:15} "
                      f"({detected.language.code}) "
                      f"Script: {detected.script.value:10} "
                      f"Confidence: {detected.confidence:.2f}")
            except Exception as e:
                print(f"‚ùå {lang_name:10} ‚Üí Error: {e}")
        
        # Test 2: Complete Processing
        print_section("2. Complete Multi-Language Processing")
        
        test_text = sample_texts['English']  # Start with English
        print(f"Processing: {test_text[:80]}...")
        
        try:
            result = multilang_processor.process_text(
                test_text,
                include_transliteration=True,
                include_translation=False,  # Skip translation for demo
                include_normalization=True
            )
            
            print(f"‚úÖ Language: {result.detected_language.language.name} ({result.detected_language.confidence:.2f})")
            print(f"‚úÖ Script: {result.detected_language.script.value}")
            
            if result.tokenization:
                print(f"‚úÖ Tokens: {len(result.tokenization.tokens)} tokens")
                print(f"   Sample: {result.tokenization.tokens[:5]}...")
            
            if result.entities:
                print(f"‚úÖ Entities: {len(result.entities)} found")
                for entity in result.entities[:3]:  # Show first 3
                    entity_type = entity.entity_type.value if hasattr(entity.entity_type, 'value') else str(entity.entity_type)
                    print(f"   - {entity_type}: '{entity.text}' (conf: {entity.confidence:.2f})")
            
            if result.normalized_entities:
                print(f"‚úÖ Normalized entities: {len(result.normalized_entities)} types")
                for entity_type, norm_list in result.normalized_entities.items():
                    print(f"   - {entity_type}: {len(norm_list)} items")
                    
        except Exception as e:
            print(f"‚ùå Processing failed: {e}")
        
        # Test 3: Business Intelligence Extraction
        print_section("3. Business Intelligence Extraction")
        
        try:
            intelligence = multilang_processor.extract_business_intelligence(test_text)
            
            print("üìä Language Information:")
            lang_info = intelligence['language_info']
            print(f"   Language: {lang_info['detected_language']} ({lang_info['language_code']})")
            print(f"   Script: {lang_info['script']}")
            print(f"   Confidence: {lang_info['confidence']:.2f}")
            
            print("üìä Extracted Entities:")
            entities = intelligence['entities']
            for entity_type, entity_list in entities.items():
                print(f"   {entity_type}: {len(entity_list)} items")
                for entity in entity_list[:2]:  # Show first 2 of each type
                    print(f"     - '{entity['text']}' (conf: {entity['confidence']:.2f})")
            
            print("üìä Structured Data:")
            structured = intelligence['structured_data']
            for data_type, data_list in structured.items():
                print(f"   {data_type}: {len(data_list)} items")
                for item in data_list[:1]:  # Show first item of each type
                    print(f"     - Original: '{item['original']}'")
                    print(f"     - Normalized: '{item['normalized']}'")
                    
        except Exception as e:
            print(f"‚ùå Business intelligence extraction failed: {e}")
        
        # Test 4: Normalization Demo
        print_section("4. Field Normalization Demo")
        
        normalization_tests = [
            ("Phone", "+1-408-996-1010", "phone"),
            ("Phone", "(555) 123-4567", "phone"),
            ("Amount", "$365.8 billion", "financial"),
            ("Amount", "‚Ç¨1,234.56", "financial"),
            ("Address", "1 Apple Park Way, Cupertino, CA 95014", "address"),
            ("Company ID", "12-3456789", "company_id"),
            ("Date", "2023-12-25", "date")
        ]
        
        for test_name, test_value, field_type in normalization_tests:
            try:
                if field_type == "phone":
                    from business_intel_scraper.backend.nlp.multilang.normalization import phone_normalizer
                    result = phone_normalizer.normalize_phone(test_value)
                elif field_type == "financial":
                    from business_intel_scraper.backend.nlp.multilang.normalization import financial_normalizer
                    result = financial_normalizer.normalize_amount(test_value)
                elif field_type == "address":
                    from business_intel_scraper.backend.nlp.multilang.normalization import address_normalizer
                    lang = multilang_processor.detector.language_data['en']
                    result = address_normalizer.normalize_address(test_value, lang)
                elif field_type == "company_id":
                    from business_intel_scraper.backend.nlp.multilang.normalization import company_id_normalizer
                    result = company_id_normalizer.normalize_company_id(test_value)
                elif field_type == "date":
                    from business_intel_scraper.backend.nlp.multilang.normalization import date_normalizer
                    lang = multilang_processor.detector.language_data['en']
                    result = date_normalizer.normalize_date(test_value, lang)
                else:
                    continue
                
                print(f"üîß {test_name:12} '{test_value}' ‚Üí '{result.normalized}' "
                      f"(conf: {result.confidence:.2f})")
                      
            except Exception as e:
                print(f"‚ùå {test_name:12} normalization failed: {e}")
        
        # Test 5: Cross-Language Entity Matching
        print_section("5. Cross-Language Entity Matching")
        
        try:
            from business_intel_scraper.backend.nlp.multilang.transliteration import entity_normalizer
            
            # Test company name matching across languages
            companies = [
                ("Apple Inc.", multilang_processor.detector.language_data['en']),
                ("ËãπÊûúÂÖ¨Âè∏", multilang_processor.detector.language_data['zh']),
                ("Samsung Electronics", multilang_processor.detector.language_data['en']),
                ("ÏÇºÏÑ±Ï†ÑÏûê", multilang_processor.detector.language_data.get('ko', multilang_processor.detector.language_data['en']))
            ]
            
            normalized_companies = []
            for company_name, language in companies:
                try:
                    normalized = entity_normalizer.normalize_company_name(company_name, language)
                    normalized_companies.append((company_name, normalized))
                    
                    print(f"üè¢ {company_name:20} ({language.code}):")
                    print(f"   Original: {normalized.get('original', 'N/A')}")
                    print(f"   Cleaned: {normalized.get('cleaned', 'N/A')}")
                    if 'transliterated' in normalized:
                        print(f"   Transliterated: {normalized['transliterated']}")
                    if 'translated' in normalized:
                        print(f"   Translated: {normalized['translated']}")
                        
                except Exception as e:
                    print(f"‚ùå Failed to normalize {company_name}: {e}")
            
            # Calculate similarities
            if len(normalized_companies) >= 2:
                print("\nüîó Similarity Scores:")
                for i in range(len(normalized_companies)):
                    for j in range(i+1, len(normalized_companies)):
                        try:
                            name1, norm1 = normalized_companies[i]
                            name2, norm2 = normalized_companies[j]
                            similarity = entity_normalizer.calculate_similarity(norm1, norm2)
                            print(f"   {name1} ‚Üî {name2}: {similarity:.3f}")
                        except Exception as e:
                            print(f"‚ùå Similarity calculation failed: {e}")
                            
        except Exception as e:
            print(f"‚ùå Cross-language matching failed: {e}")
        
        # Test 6: Batch Processing
        print_section("6. Batch Processing Demo")
        
        try:
            # Process multiple texts
            batch_texts = list(sample_texts.values())[:3]  # First 3 texts
            print(f"Processing {len(batch_texts)} texts in batch...")
            
            results = multilang_processor.batch_process(
                batch_texts,
                include_translation=False,
                include_normalization=False  # Skip for faster demo
            )
            
            for i, result in enumerate(results):
                if hasattr(result, 'detected_language'):
                    print(f"üìù Text {i+1}: {result.detected_language.language.name} "
                          f"({len(result.entities)} entities)")
                else:
                    print(f"‚ùå Text {i+1}: Processing failed")
                    
        except Exception as e:
            print(f"‚ùå Batch processing failed: {e}")
        
        # Test 7: Capabilities Report
        print_section("7. System Capabilities")
        
        try:
            capabilities = multilang_processor.get_capabilities()
            
            print(f"üåç Supported Languages: {len(capabilities['languages'])}")
            print(f"   Languages: {', '.join(capabilities['languages'][:10])}...")
            
            print(f"üìù Scripts: {', '.join(capabilities['scripts'])}")
            
            tokenization = capabilities.get('tokenization_support', {})
            print(f"üî§ Tokenization: {len(tokenization)} language-specific tokenizers")
            
            ner = capabilities.get('ner_support', {})
            print(f"üè∑Ô∏è  NER Support:")
            if 'spacy' in ner:
                print(f"   spaCy: {len(ner['spacy'])} languages")
            if 'transformers' in ner:
                print(f"   Transformers: {', '.join(ner['transformers'])}")
            
            transliteration = capabilities.get('transliteration_support', {})
            if transliteration.get('icu_available'):
                print(f"üî§ Transliteration: ICU available")
            print(f"   Supported scripts: {', '.join(transliteration.get('supported_scripts', []))}")
            
            translation = capabilities.get('translation_support', {})
            if translation.get('google_available'):
                print(f"üåê Translation: Google Translate available")
            marian_models = translation.get('marian_models', [])
            if marian_models:
                print(f"   Offline models: {len(marian_models)} language pairs")
            
            normalization = capabilities.get('normalization_support', {})
            supported_fields = [field for field, available in normalization.items() if available]
            print(f"üîß Normalization: {', '.join(supported_fields)}")
            
        except Exception as e:
            print(f"‚ùå Capabilities report failed: {e}")
        
        # Summary
        print_section("Demo Complete")
        print("‚úÖ Multi-Language NLP system demonstration completed!")
        print("\nüìã Summary:")
        print("   - Language detection across multiple scripts")
        print("   - Tokenization with language-specific algorithms")
        print("   - Multi-language Named Entity Recognition")
        print("   - Script transliteration and translation")
        print("   - Field normalization and standardization")
        print("   - Cross-language entity matching")
        print("   - Batch and asynchronous processing")
        print("\nüöÄ The system is ready for business intelligence processing!")
        
    except Exception as e:
        print(f"‚ùå Demo failed with error: {e}")
        logger.exception("Demo execution failed")

async def async_demo():
    """Demonstrate async processing capabilities"""
    print_section("Async Processing Demo")
    
    try:
        from business_intel_scraper.backend.nlp.multilang import multilang_processor
        
        # Sample texts for async processing
        texts = [
            "Apple Inc. financial report",
            "Google revenue statistics", 
            "Microsoft quarterly earnings"
        ]
        
        print("üîÑ Processing texts asynchronously...")
        
        # Process texts asynchronously
        results = await multilang_processor.async_batch_process(texts)
        
        for i, result in enumerate(results):
            if hasattr(result, 'detected_language'):
                print(f"‚ö° Async result {i+1}: {result.detected_language.language.name}")
            else:
                print(f"‚ùå Async result {i+1}: Failed")
                
        print("‚úÖ Async processing completed!")
        
    except Exception as e:
        print(f"‚ùå Async demo failed: {e}")

if __name__ == "__main__":
    # Run main demo
    main()
    
    # Run async demo
    print("\n" + "="*60)
    asyncio.run(async_demo())
