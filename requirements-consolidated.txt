# Business Intelligence Scraper - Consolidated Requirements
# This file consolidates all dependencies for easier management
# Install with: pip install -r requirements.txt

# ===== CORE DEPENDENCIES =====
# Web Framework & API
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
strawberry-graphql[fastapi]>=0.213.0
sse-starlette>=1.6.5
python-multipart>=0.0.6
aiofiles>=23.2.0

# Database & ORM
sqlalchemy>=2.0.23
alembic>=1.12.1
psycopg2-binary>=2.9.9
aiosqlite>=0.19.0

# Caching & Message Queue
redis>=5.0.1
celery>=5.3.4

# HTTP Clients & Web Scraping
requests>=2.31.0
httpx>=0.25.2
scrapy>=2.11.0
beautifulsoup4>=4.12.2
aiohttp>=3.9.0
requests-cache>=1.1.1

# Authentication & Security
pyjwt[crypto]>=2.8.0
passlib[bcrypt]>=1.7.4
cryptography>=41.0.7
bcrypt>=4.1.2

# Browser Automation
playwright>=1.40.0
selenium>=4.15.2

# Data Processing
pandas>=2.1.4
numpy>=1.24.3

# Natural Language Processing
spacy>=3.7.2
nltk>=3.8.1
textblob>=0.17.1

# Machine Learning & AI
transformers>=4.36.0
torch>=2.1.0
scikit-learn>=1.3.0
sentence-transformers>=2.2.0
tokenizers>=0.14.1

# Computer Vision & OCR  
opencv-python>=4.8.1.78
pytesseract>=0.3.10
Pillow>=10.1.0

# Data Visualization
plotly>=5.17.0
matplotlib>=3.8.0
networkx>=3.2.1

# Monitoring & Logging
prometheus-client>=0.19.0
structlog>=23.2.0

# Async & Concurrency
gevent>=23.9.0
asyncio-mqtt>=0.11.1

# Network & Proxy
python-socks>=2.4.3
urllib3>=2.0.7
stem>=1.8.2
pysocks>=1.7.1

# ===== MULTILINGUAL NLP DEPENDENCIES =====
# Language Detection & Processing
langdetect>=1.0.9
polyglot>=16.7.4
fasttext>=0.9.2

# Tokenization for Different Languages
jieba>=0.42.1          # Chinese tokenization
mecab-python3>=1.0.5   # Japanese tokenization  
pythainlp>=4.0.0       # Thai tokenization
stanza>=1.5.0          # Universal tokenization

# Transliteration & Translation
unidecode>=1.3.4       # Unicode transliteration
transliterate>=1.10.2  # Script transliteration
PyICU>=2.10.2          # International Components for Unicode
deep-translator>=1.9.2 # Translation services

# Phonetic & Fuzzy Matching
phonetics>=1.0.5       # Phonetic algorithms
fuzzywuzzy>=0.18.0     # Fuzzy string matching
python-Levenshtein>=0.12.2  # Fast string matching

# ===== DEVELOPMENT DEPENDENCIES =====
# Install with: pip install -r requirements.txt -e .[dev]
# Testing Framework
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-mock>=3.12.0
pytest-cov>=4.1.0
factory-boy>=3.3.0

# Code Quality & Formatting
black>=23.11.0
ruff>=0.1.6
mypy>=1.7.0
pre-commit>=3.5.0

# Data Analysis & Notebooks
jupyter>=1.0.0
notebook>=7.0.0
ipykernel>=6.26.0

# Profiling & Performance
memory-profiler>=0.61.0
py-spy>=0.3.14

# ===== OPTIONAL DEPENDENCIES =====
# Environment Management
python-dotenv>=1.0.0

# Date/Time Utilities  
python-dateutil>=2.8.2

# Configuration Management
pydantic>=2.5.0
pydantic-settings>=2.1.0

# File Processing
openpyxl>=3.1.2        # Excel files
python-docx>=1.1.0     # Word documents

# Email Processing
email-validator>=2.1.0

# ===== SPACY LANGUAGE MODELS =====
# Install separately with:
# python -m spacy download en_core_web_sm
# python -m spacy download en_core_web_md
# python -m spacy download en_core_web_lg
# 
# For other languages:
# python -m spacy download de_core_news_sm  # German
# python -m spacy download fr_core_news_sm  # French
# python -m spacy download es_core_news_sm  # Spanish
# python -m spacy download zh_core_web_sm   # Chinese

# ===== INSTALLATION NOTES =====
# 1. For development: pip install -r requirements.txt
# 2. For production: pip install -r requirements.txt --no-dev
# 3. Install spaCy models after installation (see commands above)
# 4. Some packages may require system dependencies:
#    - PyICU: apt-get install libicu-dev (Ubuntu/Debian)
#    - Polyglot: apt-get install libicu-dev (Ubuntu/Debian)
#    - mecab-python3: apt-get install mecab libmecab-dev (Ubuntu/Debian)
#    - OpenCV: May need system OpenCV libraries
#    - Tesseract: apt-get install tesseract-ocr (Ubuntu/Debian)
